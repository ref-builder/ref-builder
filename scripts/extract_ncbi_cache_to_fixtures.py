"""Extract NCBI cache JSON files to Python fixtures with Pydantic models.

This script reads the test cache files and generates a Python module with
hardcoded Pydantic model instances for mocking NCBIClient.
"""

import json
from pathlib import Path

from ref_builder.ncbi.models import NCBIGenbank, NCBITaxonomy


def extract_genbank_records(cache_dir: Path) -> dict[str, NCBIGenbank]:
    """Extract GenBank records from cache."""
    records = {}
    genbank_dir = cache_dir / "genbank"

    for json_file in sorted(genbank_dir.glob("*.json")):
        with open(json_file) as f:
            data = json.load(f)

        try:
            record = NCBIGenbank.model_validate(data)
            # Use accession without version as key
            records[record.accession] = record
        except Exception as e:
            print(f"Failed to parse {json_file.name}: {e}")

    return records


def extract_taxonomy_records(cache_dir: Path) -> dict[int, NCBITaxonomy]:
    """Extract Taxonomy records from cache."""
    records = {}
    taxonomy_dir = cache_dir / "taxonomy"

    for json_file in sorted(taxonomy_dir.glob("*.json")):
        with open(json_file) as f:
            data = json.load(f)

        try:
            record = NCBITaxonomy.model_validate(data)
            records[record.id] = record
        except Exception as e:
            print(f"Failed to parse {json_file.name}: {e}")

    return records


def generate_fixture_code(
    genbank_records: dict[str, NCBIGenbank],
    taxonomy_records: dict[int, NCBITaxonomy],
) -> str:
    """Generate Python code for the fixture module."""
    lines = [
        '"""Hardcoded NCBI mock data for tests.',
        "",
        "This file was generated by scripts/extract_ncbi_cache_to_fixtures.py",
        'from the test cache at tests/files/cache_test/."""',
        "",
        "from ref_builder.models import MolType, Strandedness, Topology",
        "from ref_builder.ncbi.models import (",
        "    NCBIGenbank,",
        "    NCBILineage,",
        "    NCBIRank,",
        "    NCBISource,",
        "    NCBISourceMolType,",
        "    NCBITaxonomy,",
        "    NCBITaxonomyOtherNames,",
        ")",
        "",
        "",
    ]

    # Generate GenBank records
    lines.append("MOCK_GENBANK_RECORDS: dict[str, NCBIGenbank] = {")

    for accession, record in genbank_records.items():
        lines.append(f'    "{accession}": NCBIGenbank(')
        lines.append(f'        accession="{record.accession}",')
        lines.append(f'        accession_version="{record.accession_version}",')
        lines.append(f"        strandedness=Strandedness.{record.strandedness.name},")
        lines.append(f"        moltype=MolType.{record.moltype.name},")
        lines.append(f"        topology=Topology.{record.topology.name},")
        lines.append(f'        definition="{record.definition}",')
        lines.append(f'        organism="{record.organism}",')
        # Split long sequences across multiple lines
        seq = record.sequence
        if len(seq) > 80:
            lines.append('        sequence=(')
            for i in range(0, len(seq), 80):
                chunk = seq[i : i + 80]
                lines.append(f'            "{chunk}"')
            lines.append('        ),')
        else:
            lines.append(f'        sequence="{seq}",')

        # Source
        lines.append("        source=NCBISource(")
        lines.append(f"            taxid={record.source.taxid},")
        lines.append(f'            organism="{record.source.organism}",')
        lines.append(
            f"            mol_type=NCBISourceMolType.{record.source.mol_type.name},"
        )
        if record.source.isolate:
            lines.append(f'            isolate="{record.source.isolate}",')
        if record.source.host:
            lines.append(f'            host="{record.source.host}",')
        if record.source.segment:
            lines.append(f'            segment="{record.source.segment}",')
        if record.source.strain:
            lines.append(f'            strain="{record.source.strain}",')
        if record.source.clone:
            lines.append(f'            clone="{record.source.clone}",')
        if record.source.proviral:
            lines.append(f"            proviral={record.source.proviral},")
        if record.source.macronuclear:
            lines.append(f"            macronuclear={record.source.macronuclear},")
        if record.source.focus:
            lines.append(f"            focus={record.source.focus},")
        if record.source.transgenic:
            lines.append(f"            transgenic={record.source.transgenic},")
        lines.append("        ),")

        if record.comment:
            # Escape quotes in comment
            comment = record.comment.replace('"', '\\"')
            lines.append(f'        comment="{comment}",')

        lines.append("    ),")

    lines.append("}")
    lines.append("")
    lines.append("")

    # Generate Taxonomy records
    lines.append("MOCK_TAXONOMY_RECORDS: dict[int, NCBITaxonomy] = {")

    for taxid, record in taxonomy_records.items():
        lines.append(f"    {taxid}: NCBITaxonomy(")
        lines.append(f"        id={record.id},")
        lines.append(f'        name="{record.name}",')

        # Other names
        if any(
            [
                record.other_names.acronym,
                record.other_names.genbank_acronym,
                record.other_names.equivalent_name,
                record.other_names.synonym,
                record.other_names.includes,
            ]
        ):
            lines.append("        other_names=NCBITaxonomyOtherNames(")
            if record.other_names.acronym:
                lines.append(f"            acronym={record.other_names.acronym!r},")
            if record.other_names.genbank_acronym:
                lines.append(
                    f"            genbank_acronym={record.other_names.genbank_acronym!r},"
                )
            if record.other_names.equivalent_name:
                lines.append(
                    f"            equivalent_name={record.other_names.equivalent_name!r},"
                )
            if record.other_names.synonym:
                lines.append(f"            synonym={record.other_names.synonym!r},")
            if record.other_names.includes:
                lines.append(f"            includes={record.other_names.includes!r},")
            lines.append("        ),")

        # Lineage
        lines.append("        lineage=[")
        for lineage_item in record.lineage:
            lines.append(
                f'            NCBILineage(id={lineage_item.id}, name="{lineage_item.name}", rank="{lineage_item.rank}"),'
            )
        lines.append("        ],")

        lines.append(f"        rank=NCBIRank.{record.rank.name},")
        lines.append("    ),")

    lines.append("}")

    return "\n".join(lines)


def main():
    """Main entry point."""
    cache_dir = Path("tests/files/cache_test")
    output_file = Path("tests/fixtures/ncbi_mock_data.py")

    print(f"Extracting GenBank records from {cache_dir / 'genbank'}...")
    genbank_records = extract_genbank_records(cache_dir)
    print(f"  Found {len(genbank_records)} GenBank records")

    print(f"Extracting Taxonomy records from {cache_dir / 'taxonomy'}...")
    taxonomy_records = extract_taxonomy_records(cache_dir)
    print(f"  Found {len(taxonomy_records)} Taxonomy records")

    print(f"Generating fixture code...")
    code = generate_fixture_code(genbank_records, taxonomy_records)

    print(f"Writing to {output_file}...")
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, "w") as f:
        f.write(code)

    print("Done!")


if __name__ == "__main__":
    main()
